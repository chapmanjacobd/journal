
<p>Great point. The abundance of AI slop shortens the benefit of doubt that people will give a work before deciding that it is not worthwhile to read because it might be computer generated.</p>
<p>The mistakes that AI makes have a certain style but they are not pleasant artifacts. I'm sure it's possible for this to change--but the idea of computer generated media (outside of a research context) does feel rather soulless and demoralizing.</p>
<p>It also feels deeply unethical to pay a robot for art instead of a human. And yet people don't feel as bad paying for mass produced goods instead of handmade if one is cheaper, has fewer defects, or a better <em>design</em>.</p>
<p>Another lens for looking at authorship/legitimacy that might be useful is the concept of stylebooks in journalism and differing newspaper <em>styles</em> (bias is interesting because selection is part of editing but style is much more than bias).</p>
<p>And also the lens of mass editing where many people edit a single work. This could be a screenplay or it could be <a href="https://blog.codinghorror.com/mixing-oil-and-water-authorship-in-a-wiki-world/">Wikipedia</a>. There's also a difference in how people perceive a work (and how they edit) when they see "1,732 revisions" of edit history vs. they get something from a friend to proofread who they believe is the sole author.</p>

