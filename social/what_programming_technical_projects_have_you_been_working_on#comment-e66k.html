
<p>I've been reading a lot about LTO archival. So far I've learned that:</p>
<ul>
<li>tape is kind of a pain. Even if you think that you are storing them correctly, if you don't test your backups regularly, you might find on the day that you need it that the data is unrestorable.</li>
<li>random seeks and specific file retrieval likely doesn't scale well because it adds wear to the expensive tape drives. Although there is likely an "island of stability" here where if you have a few dozen tape libraries and mirror &gt;1GB large chunks in some S3-like system it might work pretty well... assuming you have someone on staff that could repair drives as they fail from extended use.</li>
<li>one other thing to think about is that, although some LTO tapes have lasted for more than 30 years this is likely abnormal for most home environments if you live somewhere where the humidity levels are not constant. Another thing to consider is, similar to VHS tapes, there are a lot less VHS players nowadays than 30 years ago... it's still pretty easy to find working LTO-2 drives but LTO-1 drives are already pretty rare. Yes, LTO-2 and LTO-3 drives can read LTO-1 tapes but it is still something to think about...</li>
<li>one reason why I didn't really seriously consider LTO-4 ... LTO-7 is that the quantity of tapes needed when operating at a scale where this makes financial sense is that it requires a lot of space. 384 GB of LTO-7 is already 64 tapes and that takes up quite a bit of shelf space. LTO-7 is very similar in price to LTO-8 as well.</li>
</ul>
<p>I only have a couple hundred TBs and I'm pretty content now--I'm not looking to extend into the &gt;600 TB range right now so my conclusion is that a tape drive probably doesn't make sense for me right now. But if someone wants to pay me to sign up to USENET and just download stuff then I would invest in a tape library first.</p>
<p>Other than that I've been researching parallel/cluster compute platforms like HTCondor, Nomad, Triton DataCenter, and other tools listed here: <a href="https://github.com/dstdev/awesome-hpc">https://github.com/dstdev/awesome-hpc</a>. This week I've started writing something lightweight for spinning up systemd services across PCs (a bit like <a href="https://thume.ca/2020/04/18/telefork-forking-a-process-onto-a-different-computer/">telefork</a>, <a href="https://github.com/Overv/outrun#outrun">Outrun</a>, or <a href="https://github.com/intoli/exodus">Exodus</a>) taking into account (simple polling) resource allocations like %iowait, cpu_idle, available memory and excess network capacity.</p>

